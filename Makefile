# MindBase Makefile - Docker-First Development
# æ¨™æº–ã‚³ãƒãƒ³ãƒ‰: makefile-globalæº–æ‹ 

.PHONY: help up down restart logs ps clean clean-all config test

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
.DEFAULT_GOAL := help

## help: å…¨ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§è¡¨ç¤º
help:
	@echo "MindBase - AI Conversation Knowledge Management"
	@echo ""
	@echo "Usage: make <target>"
	@echo ""
	@echo "Basic Operations:"
	@echo "  up           - Start all services (PostgreSQL + API)"
	@echo "  down         - Stop all services"
	@echo "  restart      - Restart services"
	@echo "  logs         - Show all logs"
	@echo "  logs-<svc>   - Show specific service logs (api, postgres)"
	@echo "  ps           - Show container status"
	@echo ""
	@echo "Setup:"
	@echo "  init         - Initial setup (install Ollama + pull model)"
	@echo "  install-ollama - Install Ollama via brew (Mac only)"
	@echo "  model-pull   - Pull qwen3-embedding:8b model (Mac Ollama)"
	@echo "  migrate      - Run database migrations"
	@echo ""
	@echo "Development:"
	@echo "  api-shell    - Enter API container shell"
	@echo "  db-shell     - Enter PostgreSQL shell"
	@echo "  test         - Run tests"
	@echo ""
	@echo "Cleanup:"
	@echo "  clean        - Remove local artifacts (node_modules, __pycache__)"
	@echo "  clean-all    - Complete cleanup (âš ï¸ data loss: volumes deleted)"
	@echo ""
	@echo "Information:"
	@echo "  config       - Show Docker Compose configuration"
	@echo "  health       - Check service health status"
	@echo ""
	@echo "Note: Ollama runs on Mac (brew), not Docker (GPU acceleration)"

## up: å…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
up:
	@echo "ğŸš€ Starting MindBase services..."
	@if ! command -v ollama &> /dev/null; then \
		echo "âš ï¸  Ollama not found. Run: make install-ollama"; \
		exit 1; \
	fi
	@if ! pgrep -x "ollama" > /dev/null; then \
		echo "ğŸ”„ Starting Ollama (Mac)..."; \
		ollama serve > /dev/null 2>&1 & \
		sleep 2; \
	fi
	docker compose up -d --remove-orphans
	@echo "âœ… Services started"
	@echo ""
	@echo "  API:        http://localhost:18002"
	@echo "  Ollama:     http://localhost:11434 (Mac)"
	@echo "  PostgreSQL: localhost:15433"

## down: å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
down:
	@echo "ğŸ›‘ Stopping MindBase services..."
	docker compose down --remove-orphans
	@echo "âœ… Services stopped"

## restart: ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
restart: down up

## logs: å…¨ãƒ­ã‚°è¡¨ç¤º
logs:
	docker compose logs -f

## logs-api: APIãƒ­ã‚°
logs-api:
	docker compose logs -f api

## logs-postgres: PostgreSQLãƒ­ã‚°
logs-postgres:
	docker compose logs -f postgres


## ps: ã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ…‹ç¢ºèª
ps:
	docker compose ps

## init: åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
init: install-ollama up model-pull migrate
	@echo "âœ… MindBaseåˆæœŸåŒ–å®Œäº†"

## install-ollama: Ollama ã‚’brewã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆMacï¼‰
install-ollama:
	@if command -v ollama &> /dev/null; then \
		echo "âœ… Ollama already installed"; \
	else \
		echo "ğŸ“¥ Installing Ollama via brew..."; \
		brew install ollama; \
		echo "âœ… Ollama installed"; \
	fi

## model-pull: qwen3-embedding:8bãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆMac Ollamaï¼‰
model-pull:
	@echo "ğŸ“¥ Pulling qwen3-embedding:8b model (Mac Ollama)..."
	@if ! command -v ollama &> /dev/null; then \
		echo "âŒ Ollama not found. Run: make install-ollama"; \
		exit 1; \
	fi
	ollama pull qwen3-embedding:8b
	@echo "âœ… Model downloaded"

## migrate: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
migrate:
	@echo "ğŸ—„ï¸  Running database migrations..."
	docker compose exec postgres psql -U mindbase -d mindbase -f /docker-entrypoint-initdb.d/20241217120000_mind_base_schema.sql
	@echo "âœ… Migrations completed"

## api-shell: APIã‚³ãƒ³ãƒ†ãƒŠã‚·ã‚§ãƒ«
api-shell:
	docker compose exec api bash

## db-shell: PostgreSQLã‚·ã‚§ãƒ«
db-shell:
	docker compose exec postgres psql -U mindbase -d mindbase

## test: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test:
	docker compose exec api pytest tests/ -v

## clean: ãƒ­ãƒ¼ã‚«ãƒ«æˆæœç‰©å‰Šé™¤
clean:
	@echo "ğŸ§¹ Cleaning local artifacts..."
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name "node_modules" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name ".DS_Store" -delete 2>/dev/null || true
	@echo "âœ… Cleanup complete"

## clean-all: å®Œå…¨å‰Šé™¤ï¼ˆãƒœãƒªãƒ¥ãƒ¼ãƒ å«ã‚€ï¼‰
clean-all:
	@echo "âš ï¸  WARNING: This will delete all data (PostgreSQL + Ollama models)"
	@read -p "Continue? [y/N] " -n 1 -r; \
	echo; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		docker compose down -v --remove-orphans; \
		echo "âœ… Complete cleanup done"; \
	else \
		echo "âŒ Aborted"; \
	fi

## config: Docker Composeè¨­å®šè¡¨ç¤º
config:
	docker compose config

## health: ã‚µãƒ¼ãƒ“ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
health:
	@echo "ğŸ¥ Health Status:"
	@echo ""
	@echo "PostgreSQL:"
	@docker compose exec postgres pg_isready -U mindbase || echo "  âŒ Not ready"
	@echo ""
	@echo "Ollama (Mac):"
	@ollama list 2>/dev/null || echo "  âŒ Not ready (run: ollama serve)"
	@echo ""
	@echo "API:"
	@curl -s http://localhost:18002/health | jq . || echo "  âŒ Not ready"
