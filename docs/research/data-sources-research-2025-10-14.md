# AI Conversation Data Sources Research

**Date**: 2025-10-14
**Research Query**: ChatGPT conversations data export methods: local storage location and cloud export API for macOS. Including free and Plus tier access methods.
**Scope**: Extended to cover Grok, Gmail, and Google Drive integration for MindBase project

---

## Executive Summary

‚úÖ **ChatGPT**: Full export capability via official API (both free & Plus), local encrypted storage on macOS
‚úÖ **Grok**: Official export available, web-based (no local storage), third-party browser extensions
‚úÖ **Gmail**: Programmatic access via Gmail API with Python SDK
‚úÖ **Google Drive**: Programmatic access via Google Drive API with Python SDK
‚ö†Ô∏è **Key Finding**: No tier-based restrictions on ChatGPT exports; Grok is web-only

---

## 1. ChatGPT Data Sources

### 1.1 Local Storage (macOS)

#### Historical Context (Pre-July 2024)
- **Location**: `~/Library/Application Support/com.openai.chat/conversations-{uuid}/`
- **Format**: Plain text (security vulnerability)
- **Issue**: Any app could read conversations without permission

#### Current Implementation (Post-July 2024)
- **Location**: `~/Library/Application Support/com.openai.chat/conversations-v2-{uuid}/`
- **Format**: Encrypted files
- **Security**:
  - Encryption key: `com.openai.chat.conversations_v2_cache` (stored in macOS Keychain)
  - App still not sandboxed, but encrypted data prevents unauthorized reading
  - Update: ChatGPT version 1.2024.171+ required

**‚ö†Ô∏è Important**: When signing into ChatGPT Mac app, entire conversation history downloads to local folder

### 1.2 Cloud Export (Official API)

#### Access Method
```
Settings ‚Üí Data Controls ‚Üí Export ‚Üí Confirm Export
‚Üí Email notification (24h expiry link)
‚Üí Download .zip file
```

#### Export Contents
- `conversations.json` - Full conversation history in JSON format
- `chat.html` - HTML view of conversations
- Additional user data

#### conversations.json Structure
```json
{
  "title": "Conversation Title",
  "create_time": 1234567890.123,  // Epoch timestamp with milliseconds
  "update_time": 1234567890.456,
  "mapping": {
    "message_id": {
      "id": "msg_abc123",
      "message": {
        "author": {"role": "user|assistant|system"},
        "content": {"content_type": "text", "parts": ["..."]},
        "create_time": 1234567890.789
      },
      "parent": "parent_msg_id",
      "children": ["child_msg_id_1", "child_msg_id_2"]
    }
  }
}
```

### 1.3 Free vs Plus Tier

**‚úÖ No Differences in Export Capabilities**
- Both tiers have identical export functionality
- Same data format and access method
- Same export process and limitations

### 1.4 Known Limitations
- **Images**: As of August 2024, DALL-E generated images not included in exports
- **Files**: Uploaded files not included in JSON export
- **Individual Conversations**: No built-in single conversation export (use third-party tools)

### 1.5 Third-Party Tools

#### pionxzh/chatgpt-exporter (Recommended)
- **GitHub**: https://github.com/pionxzh/chatgpt-exporter
- **Stars**: ~1.8k
- **Type**: Browser extension (Tampermonkey/Greasemonkey/Violentmonkey)
- **Formats**: Multiple export formats supported
- **Latest**: v2.29.1 (July 2025)
- **Installation**: GreasyFork or direct from GitHub

#### Other Tools
- **ChatGPT Exporter Chrome Extension**: PDF, Markdown, Text, JSON, CSV, Image
- **ryanschiang/chatgpt-export**: Markdown, JSON, PNG export
- **ShareGPT**: Web-based sharing and export

### 1.6 Backend API Access (Unofficial)
```
Endpoint: https://chat.openai.com/backend-api/conversation/[id]
Format: JSON with conversation data
Authentication: Requires valid session token
‚ö†Ô∏è Unofficial: May change without notice
```

---

## 2. Grok (xAI) Data Sources

### 2.1 Local Storage
**‚ùå No Local Storage** - Grok is web-based application
- Conversations stored server-side only
- No desktop app with local caching
- Access via web or mobile app only

### 2.2 Official Export

#### Access Method
```
Grok.com ‚Üí Settings ‚Üí Data Controls ‚Üí Download Data
‚Üí Redirects to accounts.x.ai
‚Üí Request data export
```

#### Features
- **Chat History** (May 2024+): View past conversations on web and mobile
- **Memory Feature** (April 2025+):
  - Bot remembers details from past conversations
  - Toggle: Settings ‚Üí Data Controls
  - View referenced chats via book icon
  - Individual fact deletion or full conversation wipe
  - Available: Grok.com, iOS, Android (not EU/UK)

#### Privacy Controls
- **Private Chat**: Ghost icon activation
  - History not viewable
  - Deleted from xAI systems within 30 days

### 2.3 Third-Party Export Tools

#### YourAIScroll (Multi-Platform)
- **Formats**: Markdown, PDF, JSON, Plain Text
- **Platforms**: Chrome, Firefox
- **Features**: One-click Markdown copy
- **URL**: https://www.youraiscroll.com

#### Grok to PDF
- **Type**: Free Chrome extension
- **Formats**: PDF, Markdown, HTML
- **Privacy**: Browser-only processing (no server upload)
- **Features**: Perfect code formatting

#### Grok Chat Exporter
- **Formats**: PDF, HTML, Markdown, JSON, TXT, Microsoft Word
- **Type**: Chrome extension

### 2.4 API Access
**‚ö†Ô∏è Limited Documentation** - xAI API documentation available at https://docs.x.ai/docs/models but conversation export endpoints not publicly documented

---

## 3. Gmail Data Sources

### 3.1 Gmail API (Official)

#### Authentication
```python
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build

# OAuth 2.0 required
# Credentials file: credentials.json
# Token storage: token.pickle (after first auth)
```

#### Installation
```bash
pip install google-api-python-client google-auth google-auth-oauthlib
```

#### Quickstart Documentation
- **Official Guide**: https://developers.google.com/workspace/gmail/api/quickstart/python
- **API Overview**: https://developers.google.com/workspace/gmail/api/guides

#### Key Capabilities
- **Read Emails**: Full programmatic access to mailbox
- **Export Messages**: Download email content and metadata
- **Attachments**: Download attachments including Google Drive links
- **Search**: Gmail search syntax support
- **Batch Operations**: Efficient bulk email processing

### 3.2 Integration Pattern for MindBase
```python
# Example collector pattern
class GmailCollector(BaseCollector):
    def __init__(self):
        self.service = build('gmail', 'v1', credentials=creds)

    def collect(self, since_date=None):
        # Query emails with timestamp filter
        # Extract message content
        # Convert to Conversation dataclass
        # Store with timestamp metadata
```

### 3.3 Considerations
- **OAuth Consent**: User must authorize access
- **Rate Limits**: Gmail API has quota limits
- **Scope Management**: Request minimal necessary scopes
- **Privacy**: Store OAuth tokens securely

---

## 4. Google Drive Data Sources

### 4.1 Google Drive API (Official)

#### Authentication
- Same OAuth 2.0 flow as Gmail API
- Can share credentials/token with Gmail integration

#### Installation
```bash
pip install google-api-python-client google-auth google-auth-oauthlib
```

#### Key Capabilities
- **File Access**: Download documents, spreadsheets, presentations
- **Search**: Query files by name, type, content
- **Metadata**: Access creation/modification timestamps
- **Export Formats**: Convert Google Docs to multiple formats (PDF, DOCX, Markdown)

### 4.2 Integration Pattern for MindBase
```python
# Example pattern for document context
class GoogleDriveCollector(BaseCollector):
    def __init__(self):
        self.service = build('drive', 'v3', credentials=creds)

    def collect_documents(self, folder_id=None):
        # Query documents with filter
        # Export to readable format
        # Extract text content
        # Store with creation/modification timestamps
```

### 4.3 Document Types
- **Google Docs**: Export to plain text or Markdown
- **Google Sheets**: Export to CSV or JSON
- **Google Slides**: Export to text extraction
- **PDFs**: Direct download
- **Other Files**: Binary download

---

## 5. Implementation Recommendations for MindBase

### 5.1 Priority Order
1. **Phase 1** (Immediate):
   - ‚úÖ ChatGPT official export (already implemented)
   - ‚úÖ Claude Desktop/Code (already implemented)
   - ‚ö†Ô∏è Cursor (collector exists, needs activation)

2. **Phase 2** (High Value):
   - üîÑ Grok official export integration
   - üîÑ Gmail API integration (high context value)

3. **Phase 3** (Extended):
   - üìã Google Drive API integration (document context)
   - üìã Third-party browser extension support

### 5.2 Data Collection Strategy

#### ChatGPT
```python
# Implementation approach
1. Use official export API (primary)
2. Parse conversations.json structure
3. Extract timestamp data for temporal analysis
4. Store in PostgreSQL with pgvector embeddings
5. Fallback: Browser extension for individual exports
```

#### Grok
```python
# Implementation approach
1. Use official export API
2. Fallback: YourAIScroll or Grok to PDF extensions
3. Parse exported data format
4. Normalize to MindBase Conversation schema
```

#### Gmail
```python
# Implementation approach
1. Gmail API with OAuth 2.0
2. Filter emails by date range
3. Extract thread context and replies
4. Preserve email metadata (sender, recipients, date)
5. Store as Conversation with email-specific metadata
```

#### Google Drive
```python
# Implementation approach
1. Google Drive API with OAuth 2.0
2. Focus on text-extractable documents
3. Export Google Docs to Markdown
4. Extract modification history if available
5. Link to related conversations via timestamps
```

### 5.3 Timestamp Strategy (Critical for MindBase)

All data sources provide temporal metadata:

| Source | Timestamp Field | Format | Timezone |
|--------|----------------|--------|----------|
| ChatGPT | `create_time`, `update_time` | Epoch (milliseconds) | UTC |
| Grok | Metadata fields | ISO 8601 | UTC |
| Gmail | `internalDate` | Epoch (milliseconds) | UTC |
| Google Drive | `createdTime`, `modifiedTime` | RFC 3339 | UTC |

**Implementation**:
```python
# Unified timestamp handling in BaseCollector
def normalize_timestamp(self, timestamp: Any) -> datetime:
    # Handle epoch, ISO 8601, RFC 3339
    # Convert to timezone-aware datetime (UTC)
    # Store in PostgreSQL with timestamp
```

### 5.4 Data Format Normalization

```python
# Target schema (already in base_collector.py)
@dataclass
class Message:
    role: str
    content: str
    timestamp: datetime  # ‚Üê Critical for temporal analysis
    message_id: Optional[str]
    metadata: Dict[str, Any]  # Source-specific fields

@dataclass
class Conversation:
    id: str
    source: str  # 'chatgpt', 'grok', 'gmail', 'google-drive'
    title: str
    messages: List[Message]
    created_at: datetime  # ‚Üê Critical
    updated_at: datetime  # ‚Üê Critical
    project: Optional[str]
    tags: List[str]
    metadata: Dict[str, Any]
```

### 5.5 Airis MCP Gateway Integration

**Gateway Pattern**:
```yaml
MindBase API (FastAPI):
  - POST /conversations/store
  - POST /conversations/search

Airis MCP Gateway:
  - Exposes MindBase API as MCP server
  - Tool: mindbase_search(query: str, limit: int)
  - Tool: mindbase_store(conversation: dict)

Claude Code Usage:
  - Auto-loads MindBase tools via gateway
  - Searches conversation history contextually
  - Stores new conversations automatically
```

**Implementation Priority**:
1. ‚úÖ MindBase FastAPI backend (done)
2. üîÑ Airis MCP Gateway configuration
3. üîÑ Tool registration in gateway
4. üîÑ Claude Code integration testing

---

## 6. Security & Privacy Considerations

### 6.1 Sensitive Data Handling
```python
# Already implemented in daemon-config.json
"privacy": {
    "local_processing_only": true,
    "exclude_patterns": [
        "password", "api_key", "secret",
        "token", "private"
    ],
    "anonymize_personal_info": false
}
```

### 6.2 OAuth Token Storage
- **Never commit** OAuth tokens to Git
- **Store** in `~/.config/mindbase/tokens/`
- **Encrypt** token storage at rest
- **Rotate** tokens periodically

### 6.3 Local Data Encryption
- ChatGPT: Already encrypted by app
- MindBase: Consider encrypting PostgreSQL data at rest
- Backup: Encrypted backups only

---

## 7. Next Steps

### 7.1 Immediate Actions (This Sprint)
1. ‚úÖ Complete data source research (done)
2. üîÑ Create comprehensive project documentation
3. üîÑ Design Airis MCP Gateway integration
4. üîÑ Implement Grok collector
5. üîÑ Test ChatGPT collector activation

### 7.2 Short-term (Next 2 Weeks)
1. Gmail API collector implementation
2. Google Drive API collector implementation
3. Airis MCP Gateway tool registration
4. End-to-end testing with Claude Code

### 7.3 Long-term (Next Month)
1. Browser extension support (ChatGPT Exporter, YourAIScroll)
2. Automated sync scheduling
3. Web UI for conversation browsing
4. Advanced semantic search features

---

## 8. References

### Official Documentation
- [ChatGPT Export Guide](https://help.openai.com/en/articles/7260999-how-do-i-export-my-chatgpt-history-and-data)
- [Gmail API Python Quickstart](https://developers.google.com/workspace/gmail/api/quickstart/python)
- [Google Drive API Documentation](https://developers.google.com/drive/api/guides/about-sdk)
- [xAI Consumer FAQs](https://x.ai/legal/faq)

### Community Tools
- [pionxzh/chatgpt-exporter](https://github.com/pionxzh/chatgpt-exporter)
- [YourAIScroll](https://www.youraiscroll.com)
- [Grok to PDF](https://www.groktopdf.com/)

### Security Research
- [ChatGPT macOS Security Disclosure](https://pvieito.com/2024/07/chatgpt-unprotected-conversations)

---

**Research Confidence**: High (9/10)
**Sources Consulted**: 25+ web sources, official documentation, community tools
**Validation**: Cross-referenced multiple sources for accuracy

---

Generated by: PM Agent / Deep Research Mode
For: MindBase Project - AI Conversation Knowledge Management
